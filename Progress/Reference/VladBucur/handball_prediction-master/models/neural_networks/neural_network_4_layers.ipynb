{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn import preprocessing as pre\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read final processed data\n",
    "def read_data():\n",
    "    \n",
    "    df = pd.read_csv('../../inputs/final_processed_data.csv')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def normalise_data(df):\n",
    "\n",
    "    df['height'] = df['height'] / df['height'].max()\n",
    "    df['matches_year1'] = df['matches_year1'] / df['matches_year1'].max()\n",
    "    df['matches_year2'] = df['matches_year2'] / df['matches_year2'].max()\n",
    "    df['goals_year1'] = df['goals_year1'] / df['goals_year1'].max()\n",
    "    df['goals_year2'] = df['goals_year2'] / df['goals_year2'].max()\n",
    "    df['goals_per_match_year1'] = df['goals_per_match_year1'] / df['goals_per_match_year1'].max()\n",
    "    df['goals_per_match_year2'] = df['goals_per_match_year2'] / df['goals_per_match_year2'].max()\n",
    "    df['goals_per_match_year3'] = df['goals_per_match_year3'] / df['goals_per_match_year3'].max()\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = read_data()\n",
    "df = normalise_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "\n",
    "    data = df.sort_values(by=['goals_per_match_year3'])\n",
    "\n",
    "    data = data.drop('name', 1)\n",
    "\n",
    "    y = data[['goals_per_match_year3']].values.astype('float32')\n",
    "\n",
    "    data = data.drop('goals_per_match_year3', 1)\n",
    "\n",
    "    x = data.values.astype('float32')\n",
    "\n",
    "    # split final processed data in training / validation / testing \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the best neural network\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res = K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res / (SS_tot + K.epsilon()))\n",
    "\n",
    "def fit_NN(x_train, y_train, x_val, y_val):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='softmax', input_dim=11))\n",
    "    model.add(Dense(4, activation='tanh'))\n",
    "    model.add(Dense(8, activation='tanh'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    RMS = optimizers.RMSprop(lr=0.001)\n",
    "    \n",
    "    model.compile(optimizer=RMS,\n",
    "                  loss='mean_absolute_error',\n",
    "                  metrics=[coeff_determination])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=0, save_best_only=True)\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=16, epochs=50, shuffle=False,\n",
    "              validation_data=(x_val, y_val), callbacks=[checkpointer], verbose=0)\n",
    "\n",
    "    model.load_weights('weights.hdf5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to plot model accuracy on test data\n",
    "def plot_model_accuracy_on_test_data(model, x_test, y_test):\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    plt.plot(y_pred, label='prediction')\n",
    "    plt.plot(y_test, label='true',alpha =0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title('Actual value vs predicted value (goals per match year 3)')\n",
    "    ax.scatter(y_test, y_pred, edgecolors=(0, 0, 0),alpha =0.3)\n",
    "    ax.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=4)\n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to compute best data split\n",
    "def compute_best_data_split(df, iterations):\n",
    "    \n",
    "    best_test_score = -1\n",
    "    \n",
    "    for i in tqdm(range(0, iterations)):\n",
    "        \n",
    "        x_train, y_train, x_val, y_val, x_test, y_test = split_data(df)\n",
    "        \n",
    "        model = fit_NN(x_train, y_train, x_val, y_val)\n",
    "        \n",
    "        test_score = model.evaluate(x_test, y_test, verbose=0)[1]\n",
    "        \n",
    "        if test_score > best_test_score:\n",
    "            \n",
    "            best_model = model\n",
    "            best_test_score = test_score\n",
    "            \n",
    "    plot_model_accuracy_on_test_data(best_model, x_test, y_test)\n",
    "    \n",
    "    return best_model, best_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, test_score = compute_best_data_split(df, 100)\n",
    "\n",
    "print(\"Test score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to file\n",
    "model_json = model.to_json()\n",
    "with open(\"4_layers_NN.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"4_layers_NN.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset into particular player attributes\n",
    "centre_df = df[df['center'] == 1]\n",
    "back_df = df[df['back'] == 1]\n",
    "wing_df = df[df['wing'] == 1]\n",
    "line_df = df[df['line'] == 1]\n",
    "\n",
    "short_players = df[df['height'] < df['height'].quantile(.25)]\n",
    "tall_players = df[df['height'] > df['height'].quantile(.75)]\n",
    "\n",
    "rarely_playing = df[df['matches_year2'] < df['matches_year2'].quantile(.25)]\n",
    "often_playing = df[df['matches_year2'] > df['matches_year2'].quantile(.75)]\n",
    "\n",
    "low_scoring = df[df['goals_year2'] < df['goals_year2'].quantile(.25)]\n",
    "high_scoring = df[df['goals_year2'] > df['goals_year2'].quantile(.75)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centre_x = centre_df[['center','back','wing','line','height','matches_year1','goals_year1','goals_per_match_year1',\n",
    "               'matches_year2','goals_year2','goals_per_match_year2']].values.astype('float32')\n",
    "centre_y = centre_df[['goals_per_match_year3']].values.astype('float32')\n",
    "\n",
    "back_x = back_df[['center','back','wing','line','height','matches_year1','goals_year1','goals_per_match_year1',\n",
    "               'matches_year2','goals_year2','goals_per_match_year2']].values.astype('float32')\n",
    "back_y = back_df[['goals_per_match_year3']].values.astype('float32')\n",
    "\n",
    "wing_x = wing_df[['center','back','wing','line','height','matches_year1','goals_year1','goals_per_match_year1',\n",
    "               'matches_year2','goals_year2','goals_per_match_year2']].values.astype('float32')\n",
    "wing_y = wing_df[['goals_per_match_year3']].values.astype('float32')\n",
    "\n",
    "line_x = line_df[['center','back','wing','line','height','matches_year1','goals_year1','goals_per_match_year1',\n",
    "               'matches_year2','goals_year2','goals_per_match_year2']].values.astype('float32')\n",
    "line_y = line_df[['goals_per_match_year3']].values.astype('float32')\n",
    "\n",
    "short_players_x = short_players[['center','back','wing','line','height','matches_year1','goals_year1',\n",
    "        'goals_per_match_year1','matches_year2','goals_year2','goals_per_match_year2']].values.astype('float32')\n",
    "short_players_y = short_players[['goals_per_match_year3']].values.astype('float32')\n",
    "\n",
    "tall_players_x = tall_players[['center','back','wing','line','height','matches_year1','goals_year1',\n",
    "        'goals_per_match_year1','matches_year2','goals_year2','goals_per_match_year2']].values.astype('float32')\n",
    "tall_players_y = tall_players[['goals_per_match_year3']].values.astype('float32')\n",
    "\n",
    "rarely_playing_x = rarely_playing[['center','back','wing','line','height','matches_year1','goals_year1',\n",
    "        'goals_per_match_year1','matches_year2','goals_year2','goals_per_match_year2']].values.astype('float32')\n",
    "rarely_playing_y = rarely_playing[['goals_per_match_year3']].values.astype('float32')\n",
    "\n",
    "often_playing_x = often_playing[['center','back','wing','line','height','matches_year1','goals_year1',\n",
    "        'goals_per_match_year1','matches_year2','goals_year2','goals_per_match_year2']].values.astype('float32')\n",
    "often_playing_y = often_playing[['goals_per_match_year3']].values.astype('float32')\n",
    "\n",
    "low_scoring_x = low_scoring[['center','back','wing','line','height','matches_year1','goals_year1',\n",
    "        'goals_per_match_year1','matches_year2','goals_year2','goals_per_match_year2']].values.astype('float32')\n",
    "low_scoring_y = low_scoring[['goals_per_match_year3']].values.astype('float32')\n",
    "\n",
    "high_scoring_x = high_scoring[['center','back','wing','line','height','matches_year1','goals_year1',\n",
    "        'goals_per_match_year1','matches_year2','goals_year2','goals_per_match_year2']].values.astype('float32')\n",
    "high_scoring_y = high_scoring[['goals_per_match_year3']].values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(centre_x, centre_y, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(back_x, back_y, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(wing_x, wing_y, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(line_x, line_y, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(short_players_x, short_players_y, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(tall_players_x, tall_players_y, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(rarely_playing_x, rarely_playing_y, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(often_playing_x, often_playing_y, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(low_scoring_x, low_scoring_y, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(high_scoring_x, high_scoring_y, verbose=0)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
